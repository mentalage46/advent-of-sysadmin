# Saskatoon: 웹 서버 로그에서 가장 많이 접속한 IP 찾기

이 가이드는 웹 서버 액세스 로그 파일(`/home/admin/access.log`)을 분석하여 가장 많은 요청을 보낸 IP 주소를 추출하고, 그 결과를 파일에 저장하는 방법을 설명합니다.

## 1. 문제 상황 분석 (Scenario)

- **현상**: `/home/admin/access.log` 파일에는 각 줄마다 하나의 HTTP 요청 정보가 기록되어 있으며, 줄의 시작 부분에 요청자의 IP 주소가 위치합니다.
- **목표**: 가장 많은 요청을 보낸 유일한 IP 주소를 찾아 `/home/admin/highestip.txt` 파일에 저장합니다.
- **검증**: 결과 파일의 SHA1 체크섬이 `6ef426c40652babc0d081d438b9f353709008e93`이어야 합니다.

---

## 2. 해결 방법 (Solution)

리눅스의 강력한 명령어 파이프라인(`|`)을 사용하여 한 줄의 명령어로 해결할 수 있습니다.

### 실행 명령어

```bash
awk '{print $1}' /home/admin/access.log | sort | uniq -c | sort -nr | head -n 1 | awk '{print $2}' > /home/admin/highestip.txt
```

### 단계별 설명

1.  **`awk '{print $1}'`**: 로그 파일의 각 줄에서 첫 번째 필드(IP 주소)만 추출합니다.
2.  **`sort`**: 동일한 IP 주소끼리 모이도록 정렬합니다. (`uniq` 명령어를 사용하기 위한 필수 단계)
3.  **`uniq -c`**: 중복된 줄을 하나로 합치고, 왼쪽에 해당 IP가 나타난 횟수(count)를 표시합니다.
4.  **`sort -nr`**: 숫자(`-n`)를 기준으로 역순(`-r`, 큰 숫자부터) 정렬합니다. 가장 많이 나타난 IP가 맨 위로 옵니다.
5.  **`head -n 1`**: 정렬된 결과에서 가장 첫 번째 줄(가장 빈도가 높은 IP)만 가져옵니다.
6.  **`awk '{print $2}'`**: `count IP` 형식의 출력에서 두 번째 필드인 IP 주소만 다시 추출합니다.
7.  **`> /home/admin/highestip.txt`**: 최종 결과인 IP 주소를 지정된 파일에 저장합니다.

---

## 3. 주요 리눅스 명령어 상세 설명

### 🛠 `awk`

텍스트 데이터를 스캔하고 처리하는 강력한 패턴 매칭 언어입니다. 주로 공백으로 구분된 데이터에서 특정 열(column)을 추출할 때 사용합니다.

- **`$1`**: 첫 번째 필드를 의미합니다.
- **`print`**: 지정한 내용을 출력합니다.

### 🔢 `sort`

텍스트 파일의 내용을 줄 단위로 정렬합니다.

- **`-n` (numeric-sort)**: 문자열이 아닌 숫자의 크기를 기준으로 정렬합니다.
- **`-r` (reverse)**: 정렬 결과를 역순(내림차순)으로 표시합니다.

### 🆔 `uniq`

중복된 줄을 보고하거나 제거합니다. **주의: 반드시 정렬된 데이터(`sort`)를 입력으로 받아야 합니다.**

- **`-c` (count)**: 각 줄이 몇 번 중복되었는지 횟수를 앞에 붙여줍니다.

### 🔝 `head`

파일이나 입력 스트림의 앞부분을 출력합니다.

- **`-n [숫자]`**: 출력할 줄 수를 지정합니다. `head -n 1`은 가장 첫 번째 줄만 보여줍니다.

---

## 4. 최종 검증 (Verification)

결과가 올바른지 SHA1 체크섬으로 확인할 수 있습니다.

```bash
sha1sum /home/admin/highestip.txt
```

출력된 값이 `6ef426c40652babc0d081d438b9f353709008e93`와 일치하면 정답입니다.
